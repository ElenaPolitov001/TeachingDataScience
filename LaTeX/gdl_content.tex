%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{}
\begin{center}
{\Large Introduction}
\end{center}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Underlying Commonality in Deep Learning}


\begin{itemize}

\item ``How do we design deep learning algorithms that are invariant to semantically equivalent transformations while maintaining maximum expressivity?
% \item E.g. for input set ${w,x,y,z}$ and $k=2$ ie 2-tuples, the permutations are $(w,x),(x,w),(w,y), \ldots, (z,y)$.
\item For $k=1$ its a simpler linear model, easy to compute but less expressive.
\item For $k=2$ a bit complex and costly but more expressive.
\item Data may have some inherent 'regularities' (core generation function of sorts). Like creating sample points from a function. If we know this core function, the samples are redundant, meaning more of them does not add value. This is 'inductive bias'.
\end{itemize}
	  
{\tiny (Ref: Geometric Deep Learning Blueprint (Special Edition) - Machine Learning Street talk)}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{It's all about Data}

Training data is of two main domains:
\begin{itemize}
\item Euclidean: Multi-dimensional linear/planar space. Distance between two data-points is a straight line. E.g. tabular data. Current Deep Learning models work very well with this.
\item Non-euclidean: Distance between two data-points is not a straight line. E.g. Social Networks, Meshed 3D surfaces. Recent Geometric Deep Learning are for this type of data.
\end{itemize}
	  
\begin{center}
\includegraphics[width=0.8\linewidth,keepaspectratio]{gdl1}
\end{center}

{\tiny (Ref: http://graphics.stanford.edu/courses/cs468-20-fall/)}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Why Geometric?}

\begin{itemize}
\item Euclidean geometry works on planes. But, say, for curved surfaces, like, earth, the straight line distance between two points in not really the correct (arc) distance.
\item Different types of surfaces, different rules of geometries.
\item Can there be any unification?
\item In 1872, professor Felix Klein started 'Erlangen Program' to unify all these geometries by using the concepts of Invariance and Symmetry.
\end{itemize}
	  
\begin{center}
\includegraphics[width=0.8\linewidth,keepaspectratio]{gdl2}
\end{center}

{\tiny (Ref: A gentle introduction to Geometric Deep Learning - Vitale Sparacello)}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Why Geometric?}

DNNs usually work with fixed-size structured inputs like vectors. Things get complicated with non-Euclidean data
	  
\begin{center}
\includegraphics[width=0.6\linewidth,keepaspectratio]{gdl3}
\end{center}

{\tiny (Ref:https://distill.pub/2021/understanding-gnns/)}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Example: Convolution}

\begin{itemize}
\item Convolutions work well on fixed size images and filters which share weights.
\item How can we formalize and extend this idea for other domains? 
\item Maybe applying geometric principles \ldots
\end{itemize}
	  
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Universal Approximation Theorem}

\begin{itemize}
\item Goal of Machine Learning is to learn a 'function' that approximately fits training data.
\item Universal Approximation Theorem: with just one hidden layer, they can represent combinations of step functions, allowing to approximate any continuous function with arbitrary precision
\end{itemize}
	  
\begin{center}
\includegraphics[width=0.8\linewidth,keepaspectratio]{gdl4}
\end{center}

{\tiny (Ref: https://towardsdatascience.com/geometric-foundations-of-deep-learning-94cdd45b451d)}		
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Dimensionality Curse}

\begin{itemize}
\item Things get complicated in high dimensions
\item We need an exponential number of samples to approximate even the most straightforward multidimensional function.
\item Same number of samples but additional dimensionality makes the space so big that the sample dataset becomes very sparse, thus can be statistically insignificant.
\item Example (below) Approximation of a continuous function in multiple dimensions
\end{itemize}
	  
\begin{center}
\includegraphics[width=0.8\linewidth,keepaspectratio]{gdl5}
\end{center}

{\tiny (Ref: https://towardsdatascience.com/geometric-foundations-of-deep-learning-94cdd45b451d)}		
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Dimension Reduction}

\begin{itemize}
\item Dimension reduction (by Principal Component Analysis, pCA) can be done, but thats not without losing information.
\item To overcome this problem, we can use the geometric structure of input data. This structure is formally called Geometric prior and it is useful to formalize how we should process the input data.
\end{itemize}
	  
\begin{center}
\includegraphics[width=0.8\linewidth,keepaspectratio]{gdl6}
\end{center}

{\tiny (Ref: https://medium.com/@jamesim2077/introduction-to-pca-principal-component-analysis-c26dffe2a857)}		
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Core Principles}
Blueprint of Geometric Deep Learning:
\begin{itemize}
\item Symmetry
\item Scale separation
\item Geometric stability
\end{itemize}

For example, in CNNs
\begin{itemize}
\item Locally equivalent layers, the Convolutional layers
\item Each is followed by coarsening or pooling layers
\item And the last is global invariant pooling layer, say, a classification head.
\end{itemize}
	
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Symmetry}

\begin{itemize}
\item  A symmetry of an object is simply a transformation of that object which leaves it unchanged.
\item Many symmetries in Deep Learning
\begin{itemize}
\item Weight symmetry: if you exchange weights then still the neural network is graph isomorphic.
\item Label symmetry: the dog is still a dog even if you rotate or translate it.
\end{itemize}
\item If you need all the symmetries (possible variations??) of a class then we would need just one sample to learn. Because all other samples would be semantically equivalent (correlated?).
\end{itemize}


\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Examples}

\begin{itemize}
\item A symmetry ie a transformation that preserves the structure.
\item E.g. permutations (shuffling) of set members preserves it to be a set.
\item Transformations like rotation and translation preserve relative distance between points.
\item The identity transformation is a symmetry.
\item Composing a symmetric transformation is always a symmetry.
\item Inverse of a symmetry is always a symmetry.
\item This is nothing but a Symmetry Group. 
\item Group, in mathematics, is an abstract way of representing a collection of things, which allow certain set of operations on the members. How members compose with each other.
\end{itemize}
	
\end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Geometric Prior}

\begin{itemize}
\item Data based on certain geometrical structure or principle. 
\item For 2D image, its flattened/projected(?) d-dimensional vector of pixels can be its Geometric Prior.
\item Can process images independently of any shift (CNNs)
\item Can process data projected on spheres independently of rotations
\item Can process graph data independently of isomorphism (Graph Neural Networks).
\end{itemize}
	
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Geometric Deep Learning, the abstraction}

\begin{center}
\includegraphics[width=\linewidth,keepaspectratio]{gdl11}
\end{center}

{\tiny (Ref: Geometric Deep Learning Blueprint (Special Edition) - Machine Learning Street talk)}
	
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Geometric Deep Learning}

Identifies two main priors our functions must respect to simplify the problem and injecting geometric assumptions to input data:

\begin{itemize}
\item Symmetry: is respected by functions that leave an object invariant, they must be composable, invertible, and they must contain the identity;
\item Scale Separation: the function should be stable under slight deformation of the domain.
\end{itemize}
	
	 If the class of functions we define respect these properties we can tackle any data domain.
	 
\begin{center}
\includegraphics[width=0.6\linewidth,keepaspectratio]{gdl7}
\end{center}

{\tiny (Ref: A gentle introduction to Geometric Deep Learning - Vitale Sparacello)}	
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Graphs}

See the progression \ldots

\begin{itemize}
\item In tabular data, rows are independent of each other. E.g. Regression, Classification.
\item In time-series or sequential data, the next point is dependent on previous point(s).
\item In images or spatial data, one point is dependent on the neighbors of fixed size.
\item In social networks, points are connected to each other, do not have order, can have cycle, can have direction, the most generic case, thats Graphs \ldots.
\end{itemize}
	
	{\em Data has shape, and shape has a meaning}
	


\end{frame}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Permutations}

\begin{itemize}
\item  Geometric Deep Learning tries to find functions to be  able to process graph data independently of node organization

\item  All the possible node combinations are defined by a mathematical operation called Permutation. The functions must respect: 
\begin{itemize}
\item Permutation Invariance: applying permutations shouldn’t modify the result. $f(PX,PAP^T )=f(X,A)$
\item Permutation Equivalence: it doesn’t matter if we apply permutations before or after the function. $f(PX, PAP^T)=Pf(X, A)$
\item E.g. in Convolutional Neural Networks (it doesn't matter if pixels are translated) by using Convolutions on pixels neighbors (more formally: using local equivalent processing layers).
\end{itemize}
	\end{itemize}


\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Neighborhood}


\begin{itemize}
\item Let’s define the set $N_i$ of the neighbors of node $i$ as $X_{N_i}={x_j: j  N_i}$ ie. $x_1$ has neighbors called $X_{N_1}$
\item E.g. local neighborhood of the node $x_b$ is possible to create hidden representation $h_b$ using the aggregation function $g(x_b, X_{N_b})$.
 
\end{itemize}
	
\begin{center}
\includegraphics[width=0.6\linewidth,keepaspectratio]{gdl8}
\end{center}

{\tiny (Ref: https://petar-v.com/talks/5G-CS224W.pdf)}	

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Application}


\begin{itemize}
\item Deep Graph Neural Networks are built by stacking multiple of these layers!
\item Using this blueprint is possible to train GNNs able to solve the following tasks:
\end{itemize}
	
\begin{center}
\includegraphics[width=0.6\linewidth,keepaspectratio]{gdl9}
\end{center}

{\tiny (Ref: https://petar-v.com/talks/5G-CS224W.pdf)}	

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Neighborhood Aggregation}

Defining how we compute the latent representations, using the aggregation function $g$ (aka the hidden layers) we can have different flavors of GNNs:

\begin{itemize}
\item Convolutional GNNs: they use the neighbors to compute the hidden representation of the current node. Using this approach is possible to mock CNNs by computing localized convolutions.
\item Attentional GNNs: they use a self attention mechanism similar to Transformer models to learn weights between each couple of connected nodes.
\item Message passing GNNs: they propagate node features by exchanging information between adjacent nodes.
\end{itemize}
	
\begin{center}
\includegraphics[width=0.6\linewidth,keepaspectratio]{gdl10}
\end{center}

{\tiny (Ref: https://petar-v.com/talks/5G-CS224W.pdf)}	

\end{frame}


% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \begin{frame}[fragile]\frametitle{Sample Two Columns Slide}
% \begin{columns}
    % \begin{column}[T]{0.6\linewidth}
      % \begin{itemize}
		% \item aaa
	  % \end{itemize}

    % \end{column}
    % \begin{column}[T]{0.4\linewidth}
      % \begin{itemize}
		% \item bbb
	  % \end{itemize}
    % \end{column}
  % \end{columns}
% \end{frame}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{References}

\begin{itemize}
\item A gentle introduction to Geometric Deep Learning - Vitale Sparacello
\item ``Geometric Deep Learning Blueprint (Special Edition)'' - Machine Learning Street Talk
\item Geometric Deep Learning: Grids, Groups, Graphs, Geodesics, and Gauges
https://arxiv.org/abs/2104.13478
\end{itemize}
	  
\end{frame}
