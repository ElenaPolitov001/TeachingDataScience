\section[Back]{Background}
\input{bert_background}

\section[Trs]{Transformer}
\input{bert_transformers}

% \section[Concepts]{Concepts}
% \input{bert_concepts}

% \section[Ex]{Example}
% \input{bert_example}

\section[HF]{Hugging Face}
\input{bert_huggingface}

\section[Cncl]{Conclusion}
\input{bert_conclusion}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{References}
		\begin{itemize}
		\item Course materials of Christopher Manning and John Hewitt
		\item BERT: Human Language Technologies, Dipartimento di Informatica, Giuseppe Attardi
		\item BERT Explained: A Complete Guide with Theory and Tutorial – Samia Khalid
		\item BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding – Jacob Devlin
		\item AC295 Pavlos Protopapas, Inst of Applied Computational Science, Harvard
		\item The Annotated Transformer – Sasha Rush
		\item The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning) – Jay Alammar
		\item The Illustrated Transformer – Jay Alammar
		\end{itemize}
\end{frame}
