%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{}
\begin{center}
{\Large Knowledge Graph + Language Model}

\end{center}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Why?}

\begin{itemize}
\item KnowledgeGraphs are superb at representing a domain’s data, and, together with a model, can deliver answers, though the questions need to be formulated as a query by an expert.
\item Conversely, Large Language Models (LLM) allow any user to ask a question to retrieve a comprehensive answer, but that answer will not include information drawn from the users’ domain data.
\end{itemize}
	
So, combining both will be a Win-Win situation.

{\tiny (Ref: Knowledge Graphs + Large Language Models = The ability for users to ask their own questions? - Peter Lawrence)}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{What?}

Solution: Let LLM convert verbose query to GraphQL syntax which does the information retrieval. LLM make is back into verbose answer.
	
{\tiny (Ref: Knowledge Graphs + Large Language Models = The ability for users to ask their own questions? - Peter Lawrence)}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{How?}

\begin{itemize}
\item Query : \lstinline|How is Valve-104 connected to Reflux-401?|
\item Using the OpenAI gpt-3.5-turbo LLM, provide the ontology of the RDF graph as the context prompt for the LLM.
\item Ask it to prepare some SPARQL
\end{itemize}	

\begin{lstlisting}
Sure! Here is an example of a SPARQL query that returns the sequence of nodes that connect two particular nodes, assuming that there is a unique path between them:
```
PREFIX connectivity: <http://example.org/ontology#>
SELECT ?path
WHERE {
  {
    <http://example.org/node1> (connectivity:connectedTo)+ ?path .
    ?path connectivity:connectedTo <http://example.org/node2> .
  }
}
```
This query uses the property path syntax to find all paths that connect the two nodes. The syntax `(connectivity:connectedTo)+` means that we are looking for one or more occurrences of the "connectedTo" property, which allows us to traverse a path of arbitrary length.
The query returns the variable "?path," which represents the sequence of nodes that connect the two nodes. This variable will contain a list of URIs representing the nodes in the path.
Note that this query assumes that there is a unique path between the two nodes. If there are multiple paths, or if there are cycles in the graph, the query may return multiple results or an incorrect result.
\end{lstlisting}

\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{}
\begin{center}
{\Large LinkedIn posts by Tony Seale}
\end{center}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Training data for GPT}

\begin{itemize}
\item Did you know that GPT is learning from web pages and that over 40\% of those web pages contain islands of JSON-LD?
\item You can reverse this relationship and use those islands to connect GPT's embeddings BACK to your own internal data!
\end{itemize}
	  
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Transformers as GNNs}

\begin{itemize}
\item Transformers analyse sentences by assigning importance to each word in relation to others, helping them predict or generate the next words in a sentence. 
\item This 'attention mechanism' evaluates pairwise interactions between all tokens in a sequence, and these interactions can be seen as edges in a complete graph. Thus, Transformers can be thought of as graph-based models where tokens represent nodes and attention weights represent edges.
\end{itemize}
	  
\end{frame}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Transparency and Explainability}

\begin{itemize}
\item  Language models, such as ChatGPT, can provide answers in a graph of interconnected nodes. 
\item By visualising these connections, we gain insights into their decision-making process, address biases, and ensure compliance with regulations.
\end{itemize}
	  
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Knowledge Management and Control}

\begin{itemize}
\item Connect the nodes generated by your language model to your organisation's Knowledge Graph. 
\item This integration grounds the model's output in established facts, enhancing accuracy while preventing the retrieval of outdated or incorrect information.
\end{itemize}
	  
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Alignment with Ontological Worldview}

\begin{itemize}
\item Leverage the concepts defined in your Knowledge Graph's ontology to constrain the language model. 
\item This alignment ensures that the model's output remains logically consistent with your organisation's world perspective.preventing the retrieval of outdated or incorrect information.
\end{itemize}
	  
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Alignment with Ontological Worldview}
\begin{itemize}
\item Leverage the concepts defined in your Knowledge Graph's ontology to constrain the language model. 
\item This alignment ensures that the model's output remains logically consistent with your organisation's world perspective.preventing the retrieval of outdated or incorrect information.
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Risk Assessment and Compliance}
\begin{itemize}
\item Knowledge graphs enable comprehensive risk assessment, empowering proactive identification of sensitive information, compliance risks, and ethical challenges. 
\item By leveraging this capability, you can mitigate potential issues before they escalate.
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Ethical and Fair AI}
\begin{itemize}
\item Knowledge graphs offer a rich and flexible platform to encode ethical guidelines and fairness constraints into an ontology that upholds your organisation's standards.
\item This ensures that the language model adheres to ethical principles and promotes fairness.
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Balancing Innovation and Risk Management in Today's Landscape.}
\begin{itemize}
\item In today's rapidly evolving landscape, organizations grapple with the challenge of balancing innovation and risk management. 
\item While language models like ChatGPT hold immense potential for boosting productivity and enhancing customer experiences, establishing robust governance frameworks is crucial to mitigate associated risks.
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Knowledge Graphs: A Safe Path Forward}
\begin{itemize}
\item Perhaps Knowledge graphs present a safe and effective approach for organisations looking to harness the power of language models.
\item By leveraging their capabilities, organisations can navigate the complex terrain of risk and governance while unlocking the benefits of AI-driven language models.
\end{itemize}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{frame}[fragile]\frametitle{Generalized or Specific}
\begin{itemize}
\item Large Language Models (LLMs) learn statistical approximations from text corpora, granting them generalisation, flexibility, and creativity. However, they also suffer from hallucinations, unreliability, and staleness.
\item On the other hand, databases offer accuracy, speed, and reliability but lack adaptability and intelligence.
\item Perhaps the key lies in bridging these two worlds, and that's where graphs come into play. By integrating LLMs with internal data through Knowledge Graphs, we can create a Working Memory Graph (WMG) that combines the strengths of both approaches in order to achieve a given task.
\item To build a WMG, the LLM processes a question and returns a graph of nodes using URLs as identifiers, these URLs link to ground truths stored in the organisation's Knowledge Graph. The WMG can also incorporate nodes representing conceptual understanding, establishing connections between the LLM's numerical vectors and the KG's ontological classes.
\end{itemize}
\end{frame}