# Visualization for Explain-ability

As AI goes more and more AutoML it becomes black box more and more. Deep Learning is inherently non transparent. This hurts debugging and impediments justifying predictions. It has become legally imperative to back-trace the predictions.

Explainable AI (XAI) has approaches to deal with this problem. Although there are mathematical techniques like SHAPly values and LIME for XAI, stress here would be to achieve explain-ability via Visualization and insights that come through pictures and animations.

What it is not: UI, UX or HCI design
What it is: explain-ability via visualization
Application to: AI-ML, NLP, Research papers, Education, Dashboards, etc.

Copyright (C) 2021 Yogesh H Kulkarni

	
## References
- Papers:
  - https://visxai.io/
  - https://distill.pub/
- Groups:
  - https://research.google/teams/brain/pair/
  - http://vis.cse.ust.hk/groups/xai-vis/
