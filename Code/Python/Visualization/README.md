# Viz XAI

As AI goes more and more AutoML it becomes black box more and more. Deep Learning is inherently non transparent. This hurts debugging and impediments justifying predictions. It has become legally imperative to back-trace the predictions.

Explainable AI (XAI) has approaches to deal with this problem. Although there are mathematical techniques like SHAPly values and LIME for XAI, stress here would be to achieve explainability via Visualization and insights that come through pictures and animations.

What it is not: UI, UX or HCI modeling
What it is: explainability via visualization

Copyright (C) 2021 Yogesh H Kulkarni

## To Dos
- Read papers at:
  - https://visxai.io/
  - https://distill.pub/
- Try github repos at:
  - https://github.com/rulematrix/rule-matrix-py
  - https://github.com/PAIR-code/what-if-tool
- Follow Groups at
  - https://research.google/teams/brain/pair/
  - http://vis.cse.ust.hk/groups/xai-vis/
- Do courses, playlists:
  - https://www.youtube.com/c/PAIRGoogle/videos
  - https://altair-viz.github.io/altair-tutorial/README.html
