# Visualization

As AI goes more and more AutoML it becomes black box more and more. Deep Learning is inherently non transparent. This hurts debugging and impediments justifying predictions. It has become legally imperative to back-trace the predictions.

Explainable AI (XAI) has approaches to deal with this problem. Although there are mathematical techniques like SHAPly values and LIME for XAI, stress here would be to achieve explainability via Visualization and insights that come through pictures and animations.

Copyright (C) 2021 Yogesh H Kulkarni

## To Dos
- Read papers at:
    - 4th Workshop on Visualization for AI Explainability https://visxai.io/
		- Awesome Machine Learning Visualizations https://medium.com/analytics-vidhya/awesome-machine-learning-visualizations-5208f1617ec5
		- https://distill.pub/
		- https://bost.ocks.org/mike/algorithms/
- Try github repos at:
    - https://github.com/rulematrix/rule-matrix-py
		- https://github.com/PAIR-code/what-if-tool
- Follow Groups at
		- https://research.google/teams/brain/pair/
		- http://vis.cse.ust.hk/groups/xai-vis/
- Do courses:
		- https://www.udacity.com/course/human-computer-interaction--ud400
		- https://www.youtube.com/c/PAIRGoogle/videos
		- https://altair-viz.github.io/altair-tutorial/README.html
		
## Notes
- Explainability is generally for an instance, Interpretability is for a whole model.

## References
- 